{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EcnOhCN5lwGl"
   },
   "outputs": [],
   "source": [
    "#import important functions\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression, RANSACRegressor\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from sklearn.model_selection import StratifiedKFold, KFold,ShuffleSplit\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import linear_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "NPLZ5DuLZatI",
    "outputId": "c73cbe3a-de5e-4d19-a122-a5ca8b4c2e9c"
   },
   "outputs": [],
   "source": [
    "# load data for RGB channel\n",
    "data= pd.read_csv('C:/Users/Brinda Khanal/Documents/Bidur Git Repo/padColorimetry/Data/new data/mean_pixel_RGB_2400.csv')\n",
    "\n",
    "\n",
    "# retrive dilution factor \n",
    "Dilution_Factor= data['Dilution Factor']\n",
    "\n",
    "# in each channel, calculate \"sample-reference\" values\n",
    "\n",
    "data['Diff_Red']= data['RedSample']-data['RedReference']\n",
    "data['Diff_Green']= data['GreenSample']-data['GreenReference']\n",
    "data['Diff_Blue']= data['BlueSample']-data['BlueReference']\n",
    "\n",
    "Diff_values= data[['Diff_Red','Diff_Green','Diff_Blue']]\n",
    "\n",
    "\n",
    "Diff_values.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jkU-K2GBI6zw"
   },
   "source": [
    "Code cells below is for normal linear regression and linear regression using RANSAC. Just used to test their difference in terms of r2 error. \n",
    "### No need to run these two code cells below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 370
    },
    "colab_type": "code",
    "id": "5Mph1yndqDDP",
    "outputId": "74099cbe-2c06-4816-9a17-fe40ab0bbd41"
   },
   "outputs": [],
   "source": [
    "#linear regression model taking all the channels (R,G,B, Grey) as input features \n",
    "lr = LinearRegression()\n",
    "\n",
    "kf=KFold(n_splits=5, random_state=None, shuffle=True)\n",
    "\n",
    "kf_info= kf.get_n_splits(Diff_values, Dilution_Factor) # returns the number of splitting iterations in the cross-validator\n",
    "print(kf_info) \n",
    "i=1\n",
    "\n",
    "for train_index, test_index in kf.split(Diff_values, Dilution_Factor):\n",
    "  lr.fit(Diff_values.loc[train_index],Dilution_Factor.loc[train_index])\n",
    "  print (\"For Split:\",i,\",Prediciton Value: \", lr.predict([[-8.212419,   6.876871,  -2.027549]]))\n",
    "  print (\"For Split:\",i,\",coefficients: \", lr. coef_)\n",
    "  R2= lr.score(Diff_values.loc[test_index],Dilution_Factor.loc[test_index])\n",
    "  print (\"For Split:\",i,\",Score (R2): \", R2)\n",
    "  n= test_index.shape[0] # number of samples \n",
    "  p= 3 #number of predictors used, here ,we have used 3 (i.e, L,a,b)\n",
    "  Adjusted_R2= 1- (1- R2)*((n-1)/(n-p-1))\n",
    "  print (\"Adjusted R2:\", Adjusted_R2)\n",
    "  i+=1\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 370
    },
    "colab_type": "code",
    "id": "ilBBmhDI2fJc",
    "outputId": "574b8206-01bd-47a9-f0cd-070bdc493b5e"
   },
   "outputs": [],
   "source": [
    "# using RANSAC algorithm to fit linear regression robustly\n",
    "ransac = RANSACRegressor()\n",
    "kf=KFold(n_splits=5, random_state=None, shuffle=True)\n",
    "\n",
    "kf_info= kf.get_n_splits(Diff_values, Dilution_Factor) # returns the number of splitting iterations in the cross-validator\n",
    "print(kf_info) \n",
    "i=1\n",
    "\n",
    "for train_index, test_index in kf.split(Diff_values, Dilution_Factor):\n",
    "  ransac.fit(Diff_values.loc[train_index],Dilution_Factor.loc[train_index])\n",
    "  print (\"For Split:\",i,\",Prediciton Value: \", ransac.predict([[-8.212419,   6.876871,  -2.027549]]))\n",
    "  print (\"For Split:\",i,\",coefficients: \", ransac.estimator_.coef_)\n",
    "  R2= ransac.score(Diff_values.loc[test_index],Dilution_Factor.loc[test_index])\n",
    "  print (\"For Split:\",i,\",Score (R2): \", R2)\n",
    "  n= test_index.shape[0] # number of samples \n",
    "  p= 3 #number of predictors used, here ,we have used 3 (i.e, L,a,b)\n",
    "  Adjusted_R2= 1- (1- R2)*((n-1)/(n-p-1))\n",
    "  print (\"Adjusted R2:\", Adjusted_R2)\n",
    "  i+=1\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 898
    },
    "colab_type": "code",
    "id": "Aa2HyrhifLyZ",
    "outputId": "798e7ba0-a681-4d8a-fd9e-51a12ef0bdd3"
   },
   "outputs": [],
   "source": [
    "\n",
    "### observe how dilution factor is correlated with values from each channel (R,G,B) for sample \n",
    "plt.figure(2, figsize=(15,5))\n",
    "\n",
    "\n",
    "# observe the relation between red channel value and dilution factor, for sample only\n",
    "plt.subplot(131)\n",
    "\n",
    "lr_redsample = LinearRegression()\n",
    "lr_redsample.fit(data[['RedSample']],Dilution_Factor)\n",
    "\n",
    "plt.scatter(Dilution_Factor,data['RedSample'],color='orange', marker='.',label='Sample')\n",
    "plt.plot(lr_redsample.predict(data[['RedSample']]),data['RedSample'], color='navy', linewidth=2, label='Linear regressor')\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlabel(\"Dilution Factor\")\n",
    "plt.ylabel(\"Red Channel\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# observe the relation between green channel value and dilution factor, for sample only\n",
    "plt.subplot(132)\n",
    "\n",
    "\n",
    "\n",
    "lr_greensample = LinearRegression()\n",
    "lr_greensample.fit(data[['GreenSample']],Dilution_Factor)\n",
    "\n",
    "plt.scatter(Dilution_Factor,data['GreenSample'], color='orange', marker='.',label='Sample')\n",
    "plt.plot(lr_greensample.predict(data[['GreenSample']]),data['GreenSample'], color='navy', linewidth=2, label='Linear regressor')\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlabel(\"Dilution Factor\")\n",
    "plt.ylabel(\"Green Channel\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# observe the relation between blue channel value and dilution factor, for sample only\n",
    "plt.subplot(133)\n",
    "\n",
    "t = np.arange(0.01, 0.8, 0.001)\n",
    "lr_bluesample = LinearRegression()\n",
    "lr_bluesample.fit(data[['BlueSample']],Dilution_Factor)\n",
    "\n",
    "plt.scatter(Dilution_Factor,data['BlueSample'], color='orange', marker='.',label='Sample')\n",
    "plt.plot(lr_bluesample.predict(data[['BlueSample']]),data['BlueSample'], color='navy', linewidth=2, label='Linear regressor')\n",
    "plt.plot(t,-80*np.log10(t),color='red', linewidth=2, label='Log Curve')\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel(\"Dilution Factor\")\n",
    "plt.ylabel(\"Blue Channel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 881
    },
    "colab_type": "code",
    "id": "b-9vFBBOCnOk",
    "outputId": "76252481-5b32-4956-f9f8-db615c4ab821"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.figure(1, figsize=(15,5))\n",
    "\n",
    "# observe the relation between red channel value and dilution factor, when Red value= Reference- Sample\n",
    "plt.subplot(131)\n",
    "\n",
    "lr_red = LinearRegression()\n",
    "lr_red.fit(Diff_values[['Diff_Red']],Dilution_Factor)\n",
    "plt.scatter(Dilution_Factor,Diff_values['Diff_Red'], color='yellowgreen', marker='.',label='True Value')\n",
    "plt.plot( lr_red.predict(Diff_values[['Diff_Red']]), Diff_values['Diff_Red'],color='navy', linewidth=2, label='Linear regressor')\n",
    "\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlabel(\"Dilution Factor\")\n",
    "plt.ylabel(\"Red Channel (Sample-Ref)\")\n",
    "\n",
    "# observe the relation between green channel value and dilution factor, when Green Value= Reference- Sample\n",
    "plt.subplot(132)\n",
    "\n",
    "lr_green = LinearRegression()\n",
    "lr_green.fit(Diff_values[['Diff_Green']],Dilution_Factor)\n",
    "plt.scatter(Dilution_Factor,Diff_values['Diff_Green'], color='yellowgreen', marker='.',label='True Value')\n",
    "plt.plot( lr_green.predict(Diff_values[['Diff_Green']]), Diff_values['Diff_Green'],color='navy', linewidth=2, label='Linear regressor')\n",
    "\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlabel(\"Dilution Factor\")\n",
    "plt.ylabel(\"Green Channel (Sample-Ref)\")\n",
    "\n",
    "\n",
    "# observe the relation between blue channel value and dilution factor, when Blue Value= Reference- Sample\n",
    "plt.subplot(133)\n",
    "\n",
    "t = np.arange(0.01, 0.8, 0.001)\n",
    "\n",
    "lr_blue = LinearRegression()\n",
    "lr_blue.fit(Diff_values[['Diff_Blue']],Dilution_Factor)\n",
    "plt.scatter(Dilution_Factor, Diff_values['Diff_Blue'],color='yellowgreen', marker='.',label='True Value')\n",
    "plt.plot( lr_blue.predict(Diff_values[['Diff_Blue']]), Diff_values['Diff_Blue'], color='navy', linewidth=2, label='Linear regressor')\n",
    "plt.plot(t,-80*np.log10(t),color='red', linewidth=2, label='Log Curve')\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel(\"Dilution Factor\")\n",
    "plt.ylabel(\"Blue Channel (Sample-Ref)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386
    },
    "colab_type": "code",
    "id": "18Wv_StJ2QYm",
    "outputId": "a499bb7c-d79a-41bd-925a-ea43fd3e8b9d"
   },
   "outputs": [],
   "source": [
    "#linear regression model taking all the channels (R,G,B) as input features \n",
    "lr = LinearRegression()\n",
    "\n",
    "kf=KFold(n_splits=5, random_state=None, shuffle=True)\n",
    "\n",
    "kf_info= kf.get_n_splits(Diff_values, Dilution_Factor) # returns the number of splitting iterations in the cross-validator\n",
    "print(kf_info) \n",
    "i=1\n",
    "Mean_Adj_R2=[]\n",
    "\n",
    "for train_index, test_index in kf.split(Diff_values, Dilution_Factor):\n",
    "  lr.fit(Diff_values.loc[train_index],Dilution_Factor.loc[train_index])\n",
    "  print (\"For Split:\",i,\",Prediciton Value: \", lr.predict([[-2.273275,\t91.307025,\t212.647976]]))\n",
    "  print (\"For Split:\",i,\",coefficients: \", lr. coef_)\n",
    "  R2= lr.score(Diff_values.loc[test_index],Dilution_Factor.loc[test_index])\n",
    "  print (\"For Split:\",i,\",Score (R2): \", R2)\n",
    "  n= test_index.shape[0] # number of samples \n",
    "  p= 3 #number of predictors used, here ,we have used 3 (i.e, L,a,b)\n",
    "  Adjusted_R2= 1- (1- R2)*((n-1)/(n-p-1))\n",
    "  print (\"Adjusted R2:\", Adjusted_R2)\n",
    "  Mean_Adj_R2.append(Adjusted_R2)\n",
    "  i+=1\n",
    "print (\"Mean Adjusted R2:\",np.mean(Mean_Adj_R2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "niG_6JOdLEth"
   },
   "source": [
    "The cell below was just used as a test cell to observe if channels could be correlated with the dilution factor using some higher order polynomial. \n",
    "\n",
    "### Fit the Points Using Custom Equation and Visualize 3D plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "efXTMF6qZ4g7"
   },
   "source": [
    "Test for RGB Color Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AGeMABUiemVI"
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "from mpl_toolkits import mplot3d\n",
    "plt.figure(3, figsize=(15,15))\n",
    "\n",
    "#print (Diff_values.values)\n",
    "\n",
    "## just a test data\n",
    "x = np.linspace(0, 200, 180) \n",
    "y= np.linspace(0,200,180)   \n",
    "X, Y= np.meshgrid(x, y)\n",
    "#print(X,Y)\n",
    "\n",
    "\n",
    "def func(x, a,b,c,d):\n",
    "  \n",
    "  return (a+ b*x[:,0]+c*x[:,1]+d*np.log10(10+x[:,2]))\n",
    "\n",
    "\n",
    "\n",
    "def pred(x, coff):\n",
    "  \n",
    " \n",
    "  return (coff[0]+ coff[1]*0 +coff[2]*x[0]+coff[3]*np.log10(10+x[1]))\n",
    "\n",
    "\n",
    "popt, pcov = curve_fit(func, Diff_values.values, Dilution_Factor)\n",
    "\n",
    "print (popt)\n",
    "z=pred((X,Y),popt)\n",
    "predicted_values= func(Diff_values.values,popt[0],popt[1],popt[2],popt[3])\n",
    "print (predicted_values)\n",
    "R2 = r2_score(Dilution_Factor.values, predicted_values,multioutput='variance_weighted')\n",
    "n= 144 # number of samples \n",
    "p= 3 #number of predictors used, here ,we have used 3 (i.e, L,a,b)\n",
    "Adjusted_R2= 1- (1- R2)*((n-1)/(n-p-1))\n",
    "print (\" Adjusted R2: \", Adjusted_R2)\n",
    "\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.scatter(Diff_values['Diff_Green'], Diff_values['Diff_Blue'], Dilution_Factor, color='red', marker='*')\n",
    "ax.contour3D(x, y, z, 50, cmap='binary')\n",
    "ax.view_init(20,50)\n",
    "\n",
    "'''### observe how a 2nd degree polynomial fits to the channel values (for, Reference- Sample)\n",
    "polynomial_features= PolynomialFeatures(degree=2)\n",
    "X_poly = polynomial_features.fit_transform(Diff_values[['Diff_Blue']])\n",
    "poly_reg = LinearRegression()\n",
    "poly_reg.fit(X_poly,Dilution_Factor )\n",
    "Predicted_dilution= poly_reg.predict(X_poly)\n",
    "print (poly_reg.predict(polynomial_features.fit_transform([[206.85]])))\n",
    "\n",
    "print (\"coefficients: \", model. coef_)\n",
    "\n",
    "plt.scatter(Diff_values['Diff_Blue'],Dilution_Factor, color='yellowgreen', marker='.',label='True Dilution Factor')\n",
    "plt.plot(Diff_values['Diff_Blue'], Predicted_dilution, color='navy', linewidth=2, label='Polynomial Fit')'''\n",
    "\n",
    "ax.set_xlabel('G channel')\n",
    "ax.set_ylabel('B channel')\n",
    "ax.set_zlabel('dilution factor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####regressors\n",
    "reg1 = GradientBoostingRegressor(random_state=1, n_estimators=10)\n",
    "reg2 = RandomForestRegressor(random_state=1, n_estimators=10)\n",
    "reg3 = LinearRegression()\n",
    "\n",
    "kf=KFold(n_splits=5, random_state=None, shuffle=True)\n",
    "\n",
    "kf_info= kf.get_n_splits(Diff_values, Dilution_Factor) # returns the number of splitting iterations in the cross-validator\n",
    "print(kf_info) \n",
    "i=1\n",
    "Mean_Adj_R2=[]\n",
    "\n",
    "for train_index, test_index in kf.split(Diff_values, Dilution_Factor):\n",
    "    reg1.fit(Diff_values.loc[train_index],Dilution_Factor.loc[train_index])\n",
    "    reg2.fit(Diff_values.loc[train_index],Dilution_Factor.loc[train_index])\n",
    "    reg3.fit(Diff_values.loc[train_index],Dilution_Factor.loc[train_index])\n",
    "    \n",
    "    \n",
    "    print (\"True Value:\", Dilution_Factor.loc[test_index].values) \n",
    "    print (\"For Split:\",i,\",Prediciton Value: \", reg1.predict(Diff_values.loc[test_index]))\n",
    "    print (\"True Value:\", Dilution_Factor.loc[test_index].values)\n",
    "    print (\"For Split:\",i,\",Prediciton Value: \", reg2.predict(Diff_values.loc[test_index]))\n",
    "    print (\"True Value:\", Dilution_Factor.loc[test_index].values)\n",
    "    print (\"For Split:\",i,\",Prediciton Value: \", reg3.predict(Diff_values.loc[test_index]))\n",
    "    \n",
    "    \n",
    "    R21= reg1.score(Diff_values.loc[test_index],Dilution_Factor.loc[test_index])\n",
    "    R22= reg2.score(Diff_values.loc[test_index],Dilution_Factor.loc[test_index])\n",
    "    R23= reg3.score(Diff_values.loc[test_index],Dilution_Factor.loc[test_index])\n",
    "   \n",
    "    \n",
    "    \n",
    "    n= test_index.shape[0] # number of samples \n",
    "    p= 3 #number of predictors used, here ,we have used 3 (i.e, R,G,B)\n",
    "\n",
    "    Adjusted_R21= 1- (1- R21)*((n-1)/(n-p-1))\n",
    "    Adjusted_R22= 1- (1- R22)*((n-1)/(n-p-1))\n",
    "    Adjusted_R23= 1- (1- R23)*((n-1)/(n-p-1))\n",
    "    \n",
    "    \n",
    "    print (\"Fold : \", i)\n",
    "    print (\"Adjusted R2:\", Adjusted_R21)\n",
    "    print (\"Adjusted R2:\", Adjusted_R22)\n",
    "    print (\"Adjusted R2:\", Adjusted_R23)\n",
    "    \n",
    "    i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = linear_model.BayesianRidge()\n",
    "reg.fit(X, Y)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u9-raW_iM_2S"
   },
   "source": [
    "### Now we move to HSV channel, same experiments are performed with HSV values as the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "-i6qqlBzzZTV",
    "outputId": "de75712a-031f-4673-8a7e-a30b97030a70"
   },
   "outputs": [],
   "source": [
    "# load data for HSV channels\n",
    "data= pd.read_excel('C:/Users/Brinda Khanal/Documents/Bidur Git Repo/padColorimetry/Data/mean_pixel_new_HSV.xlsx')\n",
    "\n",
    "\n",
    "# retrive dilution factor \n",
    "Dilution_Factor= data['Dilution Factor']\n",
    "\n",
    "# in each channel, calculate \"sample-reference\" values ,here we have used sample- refernce instead of reference - sample. The relation is same, just the sign is reversed.\n",
    "# This is done just to obtain the position value of H value.\n",
    "\n",
    "data['Diff_H']= data['HSample']-data['HReference']\n",
    "data['Diff_S']= data['SSample']-data['SReference']\n",
    "data['Diff_V']= data['VSample']-data['VReference']\n",
    "\n",
    "Diff_values= data[['Diff_H','Diff_S','Diff_V']]\n",
    "\n",
    "\n",
    "Diff_values.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 898
    },
    "colab_type": "code",
    "id": "IYSBsGSC0UME",
    "outputId": "71d15db8-39e1-4052-a123-c7bdc01803a2"
   },
   "outputs": [],
   "source": [
    "plt.figure(1, figsize=(15,5))\n",
    "\n",
    "# observe the relation between H channel value and dilution factor, when H value= Reference- Sample\n",
    "plt.subplot(131)\n",
    "\n",
    "lr_H = LinearRegression()\n",
    "lr_H.fit(Diff_values[['Diff_H']],Dilution_Factor)\n",
    "plt.scatter(Dilution_Factor, Diff_values['Diff_H'], color='yellowgreen', marker='.',label='True Value')\n",
    "plt.plot( lr_H.predict(Diff_values[['Diff_H']]),Diff_values['Diff_H'], color='navy', linewidth=2, label='Linear regressor')\n",
    "\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlabel(\"Dilution Factor\")\n",
    "plt.ylabel(\"H Channel (Sample-Ref)\")\n",
    "\n",
    "# observe the relation between S channel value and dilution factor, when S Value= Reference- Sample\n",
    "plt.subplot(132)\n",
    "t = np.arange(0.01, 0.8, 0.001)\n",
    "lr_S = LinearRegression()\n",
    "lr_S.fit(Diff_values[['Diff_S']],Dilution_Factor)\n",
    "plt.scatter(Dilution_Factor, Diff_values['Diff_S'],color='yellowgreen', marker='.',label='True Value')\n",
    "plt.plot(lr_S.predict(Diff_values[['Diff_S']]),Diff_values['Diff_S'],  color='navy', linewidth=2, label='Linear regressor')\n",
    "plt.plot(t,80*np.log10(t),color='red', linewidth=2, label='Log Curve')\n",
    "\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlabel(\"Dilution Factor\")\n",
    "plt.ylabel(\"S Channel (Sample-Ref)\")\n",
    "\n",
    "\n",
    "# observe the relation between V channel value and dilution factor, when V Value= Reference- Sample\n",
    "plt.subplot(133)\n",
    "\n",
    "lr_V = LinearRegression()\n",
    "lr_V.fit(Diff_values[['Diff_V']],Dilution_Factor)\n",
    "plt.scatter(Dilution_Factor, Diff_values['Diff_V'], color='yellowgreen', marker='.',label='True Value')\n",
    "plt.plot( lr_V.predict(Diff_values[['Diff_V']]), Diff_values['Diff_V'], color='navy', linewidth=2, label='Linear regressor')\n",
    "\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlabel(\"Dilution Factor\")\n",
    "plt.ylabel(\"V Channel(Sample-Ref)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386
    },
    "colab_type": "code",
    "id": "tf4_ycAZ1fJg",
    "outputId": "3af96daa-d814-4c9d-bf03-9a59729e3025"
   },
   "outputs": [],
   "source": [
    "#linear regression model taking all the channels HSV as input features \n",
    "lr = LinearRegression()\n",
    "\n",
    "kf=KFold(n_splits=5, random_state=None, shuffle=True)\n",
    "\n",
    "kf_info= kf.get_n_splits(Diff_values, Dilution_Factor) # returns the number of splitting iterations in the cross-validator\n",
    "print(kf_info) \n",
    "i=1\n",
    "Mean_Adj_R2=[]\n",
    "for train_index, test_index in kf.split(Diff_values, Dilution_Factor):\n",
    "  lr.fit(Diff_values.loc[train_index],Dilution_Factor.loc[train_index])\n",
    "  print (\"For Split:\",i,\",Prediciton Value: \", lr.predict([[8.008504,\t-226.417486,\t-2.284879]]))\n",
    "  print (\"For Split:\",i,\",coefficients: \", lr. coef_)\n",
    "  R2= lr.score(Diff_values.loc[test_index],Dilution_Factor.loc[test_index])\n",
    "  print (\"For Split:\",i,\",Score (R2): \", R2)\n",
    "  n= test_index.shape[0] # number of samples \n",
    "  p= 3 #number of predictors used, here ,we have used 3 (i.e, L,a,b)\n",
    "  Adjusted_R2= 1- (1- R2)*((n-1)/(n-p-1))\n",
    "  print (\"Adjusted R2:\", Adjusted_R2)\n",
    "  Mean_Adj_R2.append(Adjusted_R2)\n",
    "  i+=1\n",
    "print (\"Mean Adjusted R2:\",np.mean(Mean_Adj_R2))\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below was just used as a test cell to observe if channels could be correlated with the dilution factor using some higher order polynomial. \n",
    "\n",
    "### Fit the Points Using Custom Equation and Visualize 3D plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kw9NGz1hejkF"
   },
   "source": [
    "Test for HSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1518
    },
    "colab_type": "code",
    "id": "9E8VEsyDf1eh",
    "outputId": "12d68984-f18a-47ce-a976-4c63b747a577"
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "from mpl_toolkits import mplot3d\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(3, figsize=(15,15))\n",
    "\n",
    "#print (Diff_values.values)\n",
    "\n",
    "## just a test data\n",
    "x = np.linspace(-200, 50, 250) \n",
    "y= np.linspace(-200,50,250)   \n",
    "X, Y= np.meshgrid(x, y)\n",
    "#print(X,Y)\n",
    "\n",
    "\n",
    "def func(x, a,b,c,d):\n",
    "  \n",
    "  return (a+ b*x[:,0]+c*np.log10(10-x[:,1])+d*x[:,2])\n",
    "\n",
    "\n",
    "\n",
    "def pred(x, coff):\n",
    "  \n",
    " \n",
    "  return (coff[0]+ coff[1]*x[0] +coff[2]*np.log10(10-x[1])+coff[2]*0)\n",
    "\n",
    "\n",
    "popt, pcov = curve_fit(func, Diff_values.values, Dilution_Factor)\n",
    "\n",
    "print (popt)\n",
    "z=pred((X,Y),popt)\n",
    "predicted_values= func(Diff_values.values,popt[0],popt[1],popt[2],popt[3])\n",
    "print (predicted_values)\n",
    "R2 = r2_score(Dilution_Factor.values, predicted_values,multioutput='variance_weighted')\n",
    "n= 144 # number of samples \n",
    "p= 3 #number of predictors used, here ,we have used 3 (i.e, L,a,b)\n",
    "Adjusted_R2= 1- (1- R2)*((n-1)/(n-p-1))\n",
    "print (\" Adjusted R2: \", Adjusted_R2)\n",
    "\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.scatter(Diff_values['Diff_H'], Diff_values['Diff_S'], Dilution_Factor, color='red', marker='*')\n",
    "ax.contour3D(x, y, z, 50, cmap='binary')\n",
    "ax.view_init(-10,30)\n",
    "\n",
    "'''### observe how a 2nd degree polynomial fits to the channel values (for, Reference- Sample)\n",
    "polynomial_features= PolynomialFeatures(degree=2)\n",
    "X_poly = polynomial_features.fit_transform(Diff_values[['Diff_Blue']])\n",
    "poly_reg = LinearRegression()\n",
    "poly_reg.fit(X_poly,Dilution_Factor )\n",
    "Predicted_dilution= poly_reg.predict(X_poly)\n",
    "print (poly_reg.predict(polynomial_features.fit_transform([[206.85]])))\n",
    "\n",
    "print (\"coefficients: \", model. coef_)\n",
    "\n",
    "plt.scatter(Diff_values['Diff_Blue'],Dilution_Factor, color='yellowgreen', marker='.',label='True Dilution Factor')\n",
    "plt.plot(Diff_values['Diff_Blue'], Predicted_dilution, color='navy', linewidth=2, label='Polynomial Fit')'''\n",
    "\n",
    "ax.set_xlabel('H channel')\n",
    "ax.set_ylabel('S channel')\n",
    "ax.set_zlabel('dilution factor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####votingregressor\n",
    "reg1 = GradientBoostingRegressor(random_state=1, n_estimators=10)\n",
    "reg2 = RandomForestRegressor(random_state=1, n_estimators=10)\n",
    "reg3 = LinearRegression()\n",
    "ereg = VotingRegressor([('gb', reg1), ('rf', reg2), ('lr', reg3)])\n",
    "\n",
    "kf=KFold(n_splits=5, random_state=None, shuffle=True)\n",
    "\n",
    "kf_info= kf.get_n_splits(Diff_values, Dilution_Factor) # returns the number of splitting iterations in the cross-validator\n",
    "print(kf_info) \n",
    "i=1\n",
    "Mean_Adj_R2=[]\n",
    "\n",
    "for train_index, test_index in kf.split(Diff_values, Dilution_Factor):\n",
    "    reg1.fit(Diff_values.loc[train_index],Dilution_Factor.loc[train_index])\n",
    "    reg2.fit(Diff_values.loc[train_index],Dilution_Factor.loc[train_index])\n",
    "    reg3.fit(Diff_values.loc[train_index],Dilution_Factor.loc[train_index])\n",
    "    ereg.fit(Diff_values.loc[train_index],Dilution_Factor.loc[train_index])\n",
    "    \n",
    "    print (\"True Value:\", Dilution_Factor.loc[test_index].values) \n",
    "    print (\"For Split:\",i,\",Prediciton Value: \", reg1.predict(Diff_values.loc[test_index]))\n",
    "    print (\"True Value:\", Dilution_Factor.loc[test_index].values)\n",
    "    print (\"For Split:\",i,\",Prediciton Value: \", reg2.predict(Diff_values.loc[test_index]))\n",
    "    print (\"True Value:\", Dilution_Factor.loc[test_index].values)\n",
    "    print (\"For Split:\",i,\",Prediciton Value: \", reg3.predict(Diff_values.loc[test_index]))\n",
    "    print (\"True Value:\", Dilution_Factor.loc[test_index].values)\n",
    "    print (\"For Split:\",i,\",Prediciton Value: \", ereg.predict(Diff_values.loc[test_index]))\n",
    "    \n",
    "    R21= reg1.score(Diff_values.loc[test_index],Dilution_Factor.loc[test_index])\n",
    "    R22= reg2.score(Diff_values.loc[test_index],Dilution_Factor.loc[test_index])\n",
    "    R23= reg3.score(Diff_values.loc[test_index],Dilution_Factor.loc[test_index])\n",
    "    R24= ereg.score(Diff_values.loc[test_index],Dilution_Factor.loc[test_index])\n",
    "    \n",
    "    \n",
    "    \n",
    "    n= test_index.shape[0] # number of samples \n",
    "    p= 3 #number of predictors used, here ,we have used 3 (i.e, R,G,B)\n",
    "\n",
    "    Adjusted_R21= 1- (1- R21)*((n-1)/(n-p-1))\n",
    "    Adjusted_R22= 1- (1- R22)*((n-1)/(n-p-1))\n",
    "    Adjusted_R23= 1- (1- R23)*((n-1)/(n-p-1))\n",
    "    Adjusted_R24= 1- (1- R24)*((n-1)/(n-p-1))\n",
    "    \n",
    "    print (\"Fold : \", i)\n",
    "    print (\"Adjusted R2:\", Adjusted_R21)\n",
    "    print (\"Adjusted R2:\", Adjusted_R22)\n",
    "    print (\"Adjusted R2:\", Adjusted_R23)\n",
    "    print (\"Adjusted R2:\", Adjusted_R24)\n",
    "\n",
    "    i+=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GuXqcdcuN7JP"
   },
   "source": [
    "### Same experiments are repeated for the values in Lab space, when they are used as the input features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "Opz-vDBcDzM7",
    "outputId": "8ffbbc6b-54f3-467a-a768-3ce934049c46"
   },
   "outputs": [],
   "source": [
    "##### load the xlsx file (the given file)\n",
    "\n",
    "# load data\n",
    "data= pd.read_excel('C:/Users/Brinda Khanal/Documents/Bidur Git Repo/padColorimetry/Data/mean_pixel_new_LAB.xlsx')\n",
    "\n",
    "\n",
    "# retrive dilution factor \n",
    "Dilution_Factor= data['Dilution Factor']\n",
    "\n",
    "# in each channel, calculate \"reference-sample\" values\n",
    "\n",
    "data['Diff_L']= data['LSample']-data['LReference']\n",
    "data['Diff_a']= data['aSample']-data['aReference']\n",
    "data['Diff_b']= data['bSample']-data['bReference']\n",
    "\n",
    "Diff_values= data[['Diff_L','Diff_a','Diff_b']]\n",
    "\n",
    "\n",
    "Diff_values.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 898
    },
    "colab_type": "code",
    "id": "9UJfsBzQCRgX",
    "outputId": "302c222a-bee8-4997-f907-f74fa221de7e"
   },
   "outputs": [],
   "source": [
    "\n",
    "############plot for the Lab color space\n",
    "\n",
    "plt.figure(1, figsize=(15,5))\n",
    "\n",
    "# observe the relation between L value and dilution factor, when L value= Reference- Sample\n",
    "plt.subplot(131)\n",
    "\n",
    "lr_L = LinearRegression()\n",
    "lr_L.fit(Diff_values[['Diff_L']],Dilution_Factor)\n",
    "plt.scatter(Dilution_Factor, Diff_values['Diff_L'],color='yellowgreen', marker='.',label='True Value')\n",
    "plt.plot(lr_L.predict(Diff_values[['Diff_L']]),Diff_values['Diff_L'],  color='navy', linewidth=2, label='Linear regressor')\n",
    "\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlabel(\"Dilution Factor\")\n",
    "plt.ylabel(\"L Channel (Sample-Ref)\")\n",
    "\n",
    "# observe the relation between a value and dilution factor, when a Value= Reference- Sample\n",
    "plt.subplot(132)\n",
    "\n",
    "lr_a = LinearRegression()\n",
    "lr_a.fit(Diff_values[['Diff_a']],Dilution_Factor)\n",
    "plt.scatter(Dilution_Factor,Diff_values['Diff_a'], color='yellowgreen', marker='.',label='True Value')\n",
    "plt.plot( lr_a.predict(Diff_values[['Diff_a']]),Diff_values['Diff_a'], color='navy', linewidth=2, label='Linear regressor')\n",
    "\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlabel(\"Dilution Factor\")\n",
    "plt.ylabel(\"a Channel (Sample- Ref)\")\n",
    "\n",
    "\n",
    "# observe the relation between b value and dilution factor, when b Value= Reference- Sample\n",
    "plt.subplot(133)\n",
    "t = np.arange(0.01, 0.8, 0.001)\n",
    "\n",
    "lr_b = LinearRegression()\n",
    "lr_b.fit(Diff_values[['Diff_b']],Dilution_Factor)\n",
    "plt.scatter(Dilution_Factor, Diff_values['Diff_b'], color='yellowgreen', marker='.',label='True Value')\n",
    "plt.plot( lr_b.predict(Diff_values[['Diff_b']]), Diff_values['Diff_b'],color='navy', linewidth=2, label='Linear regressor')\n",
    "plt.plot(t,10+15*np.log10(t),color='red', linewidth=2, label='Log Curve')\n",
    "\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlabel(\"Dilution Factor\")\n",
    "plt.ylabel(\"b (Sample- Ref) Channel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 399
    },
    "colab_type": "code",
    "id": "H6bEUbbYOWPu",
    "outputId": "b48bc992-5931-4f2e-877c-09cccfc6d99b"
   },
   "outputs": [],
   "source": [
    "#linear regression model taking all the channels L,a,b as input features \n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "kf=KFold(n_splits=5, random_state=None, shuffle=True)\n",
    "\n",
    "kf_info= kf.get_n_splits(Diff_values, Dilution_Factor) # returns the number of splitting iterations in the cross-validator\n",
    "print(kf_info) \n",
    "i=1\n",
    "Mean_Adj_R2=[]\n",
    "for train_index, test_index in kf.split(Diff_values, Dilution_Factor):\n",
    "  lr.fit(Diff_values.loc[train_index],Dilution_Factor.loc[train_index])\n",
    "  print (\"For Split:\",i,\",Prediciton Value: \", lr.predict([[-8.212419,   6.876871,  -2.027549]]))  #just testing an example\n",
    "  print (\"For Split:\",i,\",coefficients: \", lr. coef_)\n",
    "  R2= lr.score(Diff_values.loc[test_index],Dilution_Factor.loc[test_index])\n",
    "  print (\"For Split:\",i,\",Score (R2): \", R2)\n",
    "  n= test_index.shape[0] # number of samples \n",
    "  p= 3 #number of predictors used, here ,we have used 3 (i.e, L,a,b)\n",
    "  Adjusted_R2= 1- (1- R2)*((n-1)/(n-p-1))\n",
    "  print (\"Adjusted R2:\", Adjusted_R2)\n",
    "  Mean_Adj_R2.append(Adjusted_R2)\n",
    "  i+=1\n",
    "print (\"Mean Adjusted R2:\",np.mean(Mean_Adj_R2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below was just used as a test cell to observe if channels could be correlated with the dilution factor using some higher order polynomial. \n",
    "\n",
    "### Fit the Points Using Custom Equation and Visualize 3D plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fRKAnQRxZz8G"
   },
   "source": [
    "Test for Lab Color Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1332
    },
    "colab_type": "code",
    "id": "tZ5Yv2spr7pk",
    "outputId": "c030e885-1200-45c7-d1a2-90d7f5657bfa"
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "from mpl_toolkits import mplot3d\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(3, figsize=(15,15))\n",
    "\n",
    "#print (Diff_values.values)\n",
    "\n",
    "## just a test data\n",
    "x = np.linspace(-80, 80, 180) \n",
    "y= np.linspace(-80,80,180)   \n",
    "X, Y= np.meshgrid(x, y)\n",
    "#print(X,Y)\n",
    "\n",
    "\n",
    "def func(x, a,b,c,d):\n",
    "  \n",
    "  return (a+ b*x[:,1]+c*np.log10(10-x[:,2])+d*x[:,0])\n",
    "\n",
    "\n",
    "\n",
    "def pred(x, coff):\n",
    "  \n",
    " \n",
    "  return (coff[0]+ coff[1]*x[0]+coff[2]*np.log10(10-x[1])+coff[3]*0)\n",
    "\n",
    "\n",
    "popt, pcov = curve_fit(func, Diff_values.values, Dilution_Factor)\n",
    "\n",
    "print (popt)\n",
    "z=pred((X,Y),popt)\n",
    "predicted_values= func(Diff_values.values,popt[0],popt[1],popt[2],popt[3])\n",
    "print (predicted_values)\n",
    "R2 = r2_score(Dilution_Factor.values, predicted_values,multioutput='variance_weighted')\n",
    "n= 144 # number of samples \n",
    "p= 3 #number of predictors used, here ,we have used 3 (i.e, L,a,b)\n",
    "Adjusted_R2= 1- (1- R2)*((n-1)/(n-p-1))\n",
    "print (\" Adjusted R2: \", Adjusted_R2)\n",
    "\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.scatter(Diff_values['Diff_a'], Diff_values['Diff_b'], Dilution_Factor, color='red', marker='*')\n",
    "ax.contour3D(x, y, z, 50, cmap='binary')\n",
    "ax.view_init(25,40)\n",
    "\n",
    "'''### observe how a 2nd degree polynomial fits to the channel values (for, Reference- Sample)\n",
    "polynomial_features= PolynomialFeatures(degree=2)\n",
    "X_poly = polynomial_features.fit_transform(Diff_values[['Diff_Blue']])\n",
    "poly_reg = LinearRegression()\n",
    "poly_reg.fit(X_poly,Dilution_Factor )\n",
    "Predicted_dilution= poly_reg.predict(X_poly)\n",
    "print (poly_reg.predict(polynomial_features.fit_transform([[206.85]])))\n",
    "\n",
    "print (\"coefficients: \", model. coef_)\n",
    "\n",
    "plt.scatter(Diff_values['Diff_Blue'],Dilution_Factor, color='yellowgreen', marker='.',label='True Dilution Factor')\n",
    "plt.plot(Diff_values['Diff_Blue'], Predicted_dilution, color='navy', linewidth=2, label='Polynomial Fit')'''\n",
    "\n",
    "ax.set_xlabel('a channel')\n",
    "ax.set_ylabel('b channel')\n",
    "ax.set_zlabel('dilution factor')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####votingregressor\n",
    "reg1 = GradientBoostingRegressor(random_state=1, n_estimators=10)\n",
    "reg2 = RandomForestRegressor(random_state=1, n_estimators=10)\n",
    "reg3 = LinearRegression()\n",
    "ereg = VotingRegressor([('gb', reg1), ('rf', reg2), ('lr', reg3)])\n",
    "\n",
    "kf=KFold(n_splits=5, random_state=None, shuffle=True)\n",
    "\n",
    "kf_info= kf.get_n_splits(Diff_values, Dilution_Factor) # returns the number of splitting iterations in the cross-validator\n",
    "print(kf_info) \n",
    "i=1\n",
    "Mean_Adj_R2=[]\n",
    "\n",
    "for train_index, test_index in kf.split(Diff_values, Dilution_Factor):\n",
    "    reg1.fit(Diff_values.loc[train_index],Dilution_Factor.loc[train_index])\n",
    "    reg2.fit(Diff_values.loc[train_index],Dilution_Factor.loc[train_index])\n",
    "    reg3.fit(Diff_values.loc[train_index],Dilution_Factor.loc[train_index])\n",
    "    ereg.fit(Diff_values.loc[train_index],Dilution_Factor.loc[train_index])\n",
    "    \n",
    "    print (\"True Value:\", Dilution_Factor.loc[test_index].values) \n",
    "    print (\"For Split:\",i,\",Prediciton Value: \", reg1.predict(Diff_values.loc[test_index]))\n",
    "    print (\"True Value:\", Dilution_Factor.loc[test_index].values)\n",
    "    print (\"For Split:\",i,\",Prediciton Value: \", reg2.predict(Diff_values.loc[test_index]))\n",
    "    print (\"True Value:\", Dilution_Factor.loc[test_index].values)\n",
    "    print (\"For Split:\",i,\",Prediciton Value: \", reg3.predict(Diff_values.loc[test_index]))\n",
    "    print (\"True Value:\", Dilution_Factor.loc[test_index].values)\n",
    "    print (\"For Split:\",i,\",Prediciton Value: \", ereg.predict(Diff_values.loc[test_index]))\n",
    "    \n",
    "    R21= reg1.score(Diff_values.loc[test_index],Dilution_Factor.loc[test_index])\n",
    "    R22= reg2.score(Diff_values.loc[test_index],Dilution_Factor.loc[test_index])\n",
    "    R23= reg3.score(Diff_values.loc[test_index],Dilution_Factor.loc[test_index])\n",
    "    R24= ereg.score(Diff_values.loc[test_index],Dilution_Factor.loc[test_index])\n",
    "    \n",
    "    \n",
    "    \n",
    "    n= test_index.shape[0] # number of samples \n",
    "    p= 3 #number of predictors used, here ,we have used 3 (i.e, R,G,B)\n",
    "\n",
    "    Adjusted_R21= 1- (1- R21)*((n-1)/(n-p-1))\n",
    "    Adjusted_R22= 1- (1- R22)*((n-1)/(n-p-1))\n",
    "    Adjusted_R23= 1- (1- R23)*((n-1)/(n-p-1))\n",
    "    Adjusted_R24= 1- (1- R24)*((n-1)/(n-p-1))\n",
    "    \n",
    "    print (\"Fold : \", i)\n",
    "    print (\"Adjusted R2:\", Adjusted_R21)\n",
    "    print (\"Adjusted R2:\", Adjusted_R22)\n",
    "    print (\"Adjusted R2:\", Adjusted_R23)\n",
    "    print (\"Adjusted R2:\", Adjusted_R24)\n",
    "\n",
    "    i+=1\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Regression_and_scatter_plots.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
