{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contains all the code to perform to train and test small fully connected ANN and CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import cv2\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_squared_error,accuracy_score, confusion_matrix,roc_auc_score,classification_report\n",
    "from sklearn.model_selection import StratifiedKFold, KFold,ShuffleSplit\n",
    "from keras.optimizers import SGD\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation, BatchNormalization, SpatialDropout2D\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the mean pixel values from the csv file and train/test fully connected ANN\n",
    "### 2. Load the pixel values from the pickle file (the pixel values are used as features) and train/test CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load downsampled pixels values of trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_RGB():\n",
    "    \n",
    "    # load RGB channel data\n",
    "    data= pd.read_pickle('C:/Users/Brinda Khanal/Documents/Bidur Git Repo/padColorimetry/Data/new data/downsampled_image_RGB_32_2400.pkl')\n",
    "    replace_values= { 1:11, 2 : 11, 3 : 11, 4 : 12, 5 : 12, 6 : 12 , 7 : 12, 8 : 13, 9 : 13, 10 : 13} # fuse the labels\n",
    "    data.replace({'Dilution Factor' : replace_values}, inplace = True)\n",
    "\n",
    "    # encode the label values into integer type\n",
    "    lab_enc = preprocessing.LabelEncoder()\n",
    "    Label = lab_enc.fit_transform(data['Dilution Factor'])\n",
    "    \n",
    "    feature_vector = data['Feature Vector']\n",
    "    features=[]\n",
    "    \n",
    "\n",
    "    for f in feature_vector:\n",
    "        features.append(f)\n",
    "        \n",
    "    features = np.array(features)\n",
    "    image1 = np.split(features, 2,axis=3)[0]\n",
    "    image2 = np.split(features, 2, axis=3)[1] \n",
    "    print (image1.shape)\n",
    "    print (image2.shape)\n",
    "    \n",
    "    plt.subplot(121).axis('off')\n",
    "    plt.imshow(image1[190][:,:,::-1])\n",
    "\n",
    "    plt.subplot(122).axis('off')\n",
    "    plt.imshow(image2[190][:,:,::-1])\n",
    "    \n",
    "    print (features.shape)\n",
    "    features = np.reshape(features,(features.shape[0],-1))\n",
    "\n",
    "    return Label, features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_HSV():\n",
    "    \n",
    "    # load RGB channel data\n",
    "    data= pd.read_pickle('C:/Users/Brinda Khanal/Documents/Bidur Git Repo/padColorimetry/Data/new data/downsampled_image_HSV_32_2400.pkl')\n",
    "    replace_values= { 1:11, 2 : 11, 3 : 11, 4 : 12, 5 : 12, 6 : 12 , 7 : 12, 8 : 13, 9 : 13, 10 : 13} # fuse the labels\n",
    "    data.replace({'Dilution Factor' : replace_values}, inplace = True)\n",
    "\n",
    "    # encode the label values into integer type\n",
    "    lab_enc = preprocessing.LabelEncoder()\n",
    "    Label = lab_enc.fit_transform(data['Dilution Factor'])\n",
    "    \n",
    "    feature_vector = data['Feature Vector']\n",
    "    features=[]\n",
    "    for f in feature_vector:\n",
    "        features.append(f)\n",
    "    features = np.array(features)\n",
    "    #print (features)\n",
    "\n",
    "    return Label, features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the downsampled pixels values of test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_LAB():\n",
    "    \n",
    "    # load RGB channel data\n",
    "    data= pd.read_pickle('C:/Users/Brinda Khanal/Documents/Bidur Git Repo/padColorimetry/Data/new data/downsampled_image_LAB_32_2400.pkl')\n",
    "    replace_values= { 1:11, 2 : 11, 3 : 11, 4 : 12, 5 : 12, 6 : 12 , 7 : 12, 8 : 13, 9 : 13, 10 : 13} # fuse the labels\n",
    "    data.replace({'Dilution Factor' : replace_values}, inplace = True)\n",
    "\n",
    "    # encode the label values into integer type\n",
    "    lab_enc = preprocessing.LabelEncoder()\n",
    "    Label = lab_enc.fit_transform(data['Dilution Factor'])\n",
    "    \n",
    "    feature_vector = data['Feature Vector']\n",
    "    features=[]\n",
    "    for f in feature_vector:\n",
    "        features.append(f)\n",
    "    features = np.array(features)\n",
    "    #print (features)\n",
    "\n",
    "    return Label, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_RGB_test():\n",
    "    \n",
    "    # load RGB channel data\n",
    "    data= pd.read_pickle('C:/Users/Brinda Khanal/Documents/Bidur Git Repo/padColorimetry/Data/new data/downsampled_image_RGB_32_600.pkl')\n",
    "    replace_values= { 1:11, 2 : 11, 3 : 11, 4 : 12, 5 : 12, 6 : 12 , 7 : 12, 8 : 13, 9 : 13, 10 : 13} # fuse the labels\n",
    "    data.replace({'Dilution Factor' : replace_values}, inplace = True)\n",
    "\n",
    "    # encode the label values into integer type\n",
    "    lab_enc = preprocessing.LabelEncoder()\n",
    "    Label = lab_enc.fit_transform(data['Dilution Factor'])\n",
    "    \n",
    "    feature_vector = data['Feature Vector']\n",
    "    features=[]\n",
    "    for f in feature_vector:\n",
    "        features.append(f)\n",
    "    features = np.array(features)\n",
    "    #print (features)\n",
    "\n",
    "    return Label, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_HSV_test():\n",
    "    \n",
    "    # load RGB channel data\n",
    "    data= pd.read_pickle('C:/Users/Brinda Khanal/Documents/Bidur Git Repo/padColorimetry/Data/new data/downsampled_image_RGB_32_600.pkl')\n",
    "    replace_values= { 1:11, 2 : 11, 3 : 11, 4 : 12, 5 : 12, 6 : 12 , 7 : 12, 8 : 13, 9 : 13, 10 : 13} # fuse the labels\n",
    "    data.replace({'Dilution Factor' : replace_values}, inplace = True)\n",
    "\n",
    "    # encode the label values into integer type\n",
    "    lab_enc = preprocessing.LabelEncoder()\n",
    "    Label = lab_enc.fit_transform(data['Dilution Factor'])\n",
    "    \n",
    "    feature_vector = data['Feature Vector']\n",
    "    features=[]\n",
    "    for f in feature_vector:\n",
    "        features.append(f)\n",
    "    features = np.array(features)\n",
    "    #print (features)\n",
    "\n",
    "    return Label, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_LAB_test():\n",
    "    \n",
    "    # load RGB channel data\n",
    "    data= pd.read_pickle('C:/Users/Brinda Khanal/Documents/Bidur Git Repo/padColorimetry/Data/new data/downsampled_image_RGB_32_600.pkl')\n",
    "    replace_values= { 1:11, 2 : 11, 3 : 11, 4 : 12, 5 : 12, 6 : 12 , 7 : 12, 8 : 13, 9 : 13, 10 : 13} # fuse the labels\n",
    "    data.replace({'Dilution Factor' : replace_values}, inplace = True)\n",
    "\n",
    "    # encode the label values into integer type\n",
    "    lab_enc = preprocessing.LabelEncoder()\n",
    "    Label = lab_enc.fit_transform(data['Dilution Factor'])\n",
    "    \n",
    "    feature_vector = data['Feature Vector']\n",
    "    features=[]\n",
    "    for f in feature_vector:\n",
    "        features.append(f)\n",
    "    features = np.array(features)\n",
    "    #print (features)\n",
    "\n",
    "    return Label, features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here you load the mean values form the csv files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the mean values of the trainset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_RGB_train_mean():\n",
    "    # load RGB channel data\n",
    "    data= pd.read_csv('C:/Users/Brinda Khanal/Documents/Bidur Git Repo/padColorimetry/Data/new data/mean_pixel_RGB_2400.csv')\n",
    "    replace_values= { 1:11, 2 : 11, 3 : 11, 4 : 12, 5 : 12, 6 : 12 , 7 : 12, 8 : 13, 9 : 13, 10 : 13} # fuse the labels\n",
    "    data.replace({'Dilution Factor' : replace_values}, inplace = True)\n",
    "    \n",
    "\n",
    "    # encode the label values into integer type\n",
    "    lab_enc = preprocessing.LabelEncoder()\n",
    "    encoded = lab_enc.fit_transform(data['Dilution Factor'])\n",
    "    Dilution_Factor= pd.DataFrame(encoded,columns= ['Label'])\n",
    "\n",
    "    # in each channel, calculate \"sample-reference\" values\n",
    "\n",
    "    data['Diff_Red']= data['RedSample']-data['RedReference']\n",
    "    data['Diff_Green']= data['GreenSample']-data['GreenReference']\n",
    "    data['Diff_Blue']= data['BlueSample']-data['BlueReference']\n",
    "\n",
    "    #Diff_values= data[['Diff_Red','Diff_Green','Diff_Blue']]\n",
    "    values= data[['BlueReference','BlueSample','GreenReference','GreenSample','RedReference','RedSample']]\n",
    "    values_sample=data[['BlueSample','GreenSample','RedSample']]\n",
    "\n",
    "    return Dilution_Factor, values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_HSV_train_mean():\n",
    "    # load RGB channel data\n",
    "    data= pd.read_csv('C:/Users/Brinda Khanal/Documents/Bidur Git Repo/padColorimetry/Data/new data/mean_pixel_HSV_2400.csv')\n",
    "    replace_values= { 1:11, 2 : 11, 3 : 11, 4 : 12, 5 : 12, 6 : 12 , 7 : 12, 8 : 13, 9 : 13, 10 : 13} # fuse the labels\n",
    "    data.replace({'Dilution Factor' : replace_values}, inplace = True)\n",
    "\n",
    "\n",
    "    # encode the label values into integer type\n",
    "    lab_enc = preprocessing.LabelEncoder()\n",
    "    encoded = lab_enc.fit_transform(data['Dilution Factor'])\n",
    "    Dilution_Factor= pd.DataFrame(encoded,columns= ['Label'])\n",
    "\n",
    "    # in each channel, calculate \"sample-reference\" values\n",
    "\n",
    "    data['Diff_H']= data['HSample']-data['HReference']\n",
    "    data['Diff_S']= data['SSample']-data['SReference']\n",
    "    data['Diff_V']= data['VSample']-data['VReference']\n",
    "\n",
    "    #Diff_values= data[['Diff_H','Diff_S','Diff_V']]\n",
    "    values= data[['HReference','HSample','SReference','SSample','VReference','VSample']]\n",
    "    values_sample=data[['HSample','SSample','VSample']]\n",
    "\n",
    "    return Dilution_Factor, values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_LAB_train_mean():\n",
    "    # load RGB channel data\n",
    "    data= pd.read_csv('C:/Users/Brinda Khanal/Documents/Bidur Git Repo/padColorimetry/Data/new data/mean_pixel_LAB_2400.csv')\n",
    "    replace_values= { 1:11, 2 : 11, 3 : 11, 4 : 12, 5 : 12, 6 : 12 , 7 : 12, 8 : 13, 9 : 13, 10 : 13} # fuse the labels\n",
    "    data.replace({'Dilution Factor' : replace_values}, inplace = True)\n",
    "\n",
    "\n",
    "    # encode the label values into integer type\n",
    "    lab_enc = preprocessing.LabelEncoder()\n",
    "    encoded = lab_enc.fit_transform(data['Dilution Factor'])\n",
    "    Dilution_Factor= pd.DataFrame(encoded,columns= ['Label'])\n",
    "\n",
    "    # in each channel, calculate \"sample-reference\" values\n",
    "\n",
    "    data['Diff_L']= data['LReference']-data['LSample']\n",
    "    data['Diff_a']= data['aReference']-data['aSample']\n",
    "    data['Diff_b']= data['bReference']-data['bSample']\n",
    "\n",
    "    #Diff_values= data[['Diff_L','Diff_a','Diff_b']]\n",
    "    values = data [['LReference','LSample','aReference','aSample','bReference','bSample']]\n",
    "    values_sample=data[['LSample','aSample','bSample']]\n",
    "\n",
    "    return Dilution_Factor, values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the mean value of the testsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_RGB_test_mean():\n",
    "    # load RGB channel data\n",
    "    data= pd.read_csv('C:/Users/Brinda Khanal/Documents/Bidur Git Repo/padColorimetry/Data/new data/mean_pixel_RGB_600.csv')\n",
    "    replace_values= { 1:11, 2 : 11, 3 : 11, 4 : 12, 5 : 12, 6 : 12 , 7 : 12, 8 : 13, 9 : 13, 10 : 13} # fuse the labels\n",
    "    data.replace({'Dilution Factor' : replace_values}, inplace = True)\n",
    "\n",
    "\n",
    "    # encode the label values into integer type\n",
    "    lab_enc = preprocessing.LabelEncoder()\n",
    "    encoded = lab_enc.fit_transform(data['Dilution Factor'])\n",
    "    Dilution_Factor= pd.DataFrame(encoded,columns= ['Label'])\n",
    "\n",
    "    # in each channel, calculate \"sample-reference\" values\n",
    "\n",
    "    data['Diff_Red']= data['RedSample']-data['RedReference']\n",
    "    data['Diff_Green']= data['GreenSample']-data['GreenReference']\n",
    "    data['Diff_Blue']= data['BlueSample']-data['BlueReference']\n",
    "\n",
    "    #Diff_values= data[['Diff_Red','Diff_Green','Diff_Blue']]\n",
    "    values= data[['BlueReference','BlueSample','GreenReference','GreenSample','RedReference','RedSample']]\n",
    "    values_sample=data[['BlueSample','GreenSample','RedSample']]\n",
    "\n",
    "    return Dilution_Factor, values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_HSV_test_mean():\n",
    "    # load RGB channel data\n",
    "    data= pd.read_csv('C:/Users/Brinda Khanal/Documents/Bidur Git Repo/padColorimetry/Data/new data/mean_pixel_HSV_600.csv')\n",
    "    replace_values= { 1:11, 2 : 11, 3 : 11, 4 : 12, 5 : 12, 6 : 12 , 7 : 12, 8 : 13, 9 : 13, 10 : 13} # fuse the labels\n",
    "    data.replace({'Dilution Factor' : replace_values}, inplace = True)\n",
    "\n",
    "\n",
    "    # encode the label values into integer type\n",
    "    lab_enc = preprocessing.LabelEncoder()\n",
    "    encoded = lab_enc.fit_transform(data['Dilution Factor'])\n",
    "    Dilution_Factor= pd.DataFrame(encoded,columns= ['Label'])\n",
    "\n",
    "    # in each channel, calculate \"sample-reference\" values\n",
    "\n",
    "    data['Diff_H']= data['HSample']-data['HReference']\n",
    "    data['Diff_S']= data['SSample']-data['SReference']\n",
    "    data['Diff_V']= data['VSample']-data['VReference']\n",
    "\n",
    "    #Diff_values= data[['Diff_H','Diff_S','Diff_V']]\n",
    "    values= data[['HReference','HSample','SReference','SSample','VReference','VSample']]\n",
    "    values_sample=data[['HSample','SSample','VSample']]\n",
    "\n",
    "    return Dilution_Factor, values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_LAB_test_mean():\n",
    "    # load RGB channel data\n",
    "    data= pd.read_csv('C:/Users/Brinda Khanal/Documents/Bidur Git Repo/padColorimetry/Data/new data/mean_pixel_LAB_600.csv')\n",
    "    replace_values= { 1:11, 2 : 11, 3 : 11, 4 : 12, 5 : 12, 6 : 12 , 7 : 12, 8 : 13, 9 : 13, 10 : 13} # fuse the labels\n",
    "    data.replace({'Dilution Factor' : replace_values}, inplace = True)\n",
    "\n",
    "\n",
    "    # encode the label values into integer type\n",
    "    lab_enc = preprocessing.LabelEncoder()\n",
    "    encoded = lab_enc.fit_transform(data['Dilution Factor'])\n",
    "    Dilution_Factor= pd.DataFrame(encoded,columns= ['Label'])\n",
    "\n",
    "    # in each channel, calculate \"sample-reference\" values\n",
    "\n",
    "    data['Diff_L']= data['LReference']-data['LSample']\n",
    "    data['Diff_a']= data['aReference']-data['aSample']\n",
    "    data['Diff_b']= data['bReference']-data['bSample']\n",
    "\n",
    "    #Diff_values= data[['Diff_L','Diff_a','Diff_b']]\n",
    "    values = data [['LReference','LSample','aReference','aSample','bReference','bSample']]\n",
    "    values_sample=data[['LSample','aSample','bSample']]\n",
    "\n",
    "    return Dilution_Factor, values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the features for the CNN trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_RGB_CNN():\n",
    "    \n",
    "    # load RGB channel data\n",
    "    #data= pd.read_pickle('C:/Users/Brinda Khanal/Documents/Bidur Git Repo/padColorimetry/Data/downsampled_feature_vectors_RGB_CNN.pkl')\n",
    "    #data= pd.read_pickle('C:/Users/Brinda Khanal/Documents/Bidur Git Repo/padColorimetry/Data/downsampled_feature_vectors_RGB_inner_circle_CNN.pkl')\n",
    "    data= pd.read_pickle('C:/Users/Brinda Khanal/Documents/Bidur Git Repo/padColorimetry/Data/new data/downsampled_image_RGB_32_2400.pkl')\n",
    "    #replace_values= { 1:11, 2 : 11, 3 : 11, 4 : 12, 5 : 12, 6 : 12 , 7 : 12, 8 : 13, 9 : 13, 10 : 13} # fuse the labels\n",
    "    #data.replace({'Dilution Factor' : replace_values}, inplace = True)  \n",
    "        \n",
    "    lab_enc = preprocessing.LabelEncoder()\n",
    "    Label = lab_enc.fit_transform(data['Dilution Factor'])\n",
    "    \n",
    "    feature_vector = data['Feature Vector']\n",
    "    features=[]\n",
    "    for f in feature_vector:\n",
    "        features.append(f)\n",
    "    features = np.array(features)\n",
    "    print(features.shape)\n",
    "    #datagen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)\n",
    "    #datagen.fit(features)\n",
    "    #features = (features-datagen.mean)/datagen.std\n",
    "    #features= (features-[ 82.73537,  108.89578,  121.84176,   96.675514, 118.18483,  123.833755])/[58.642254, 53.121796, 57.44918,  53.580616, 54.76519,  56.368843]\n",
    "    print (features.shape)\n",
    "\n",
    "    return Label, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_HSV_CNN():\n",
    "    \n",
    "    # load RGB channel data\n",
    "    data= pd.read_pickle('C:/Users/Brinda Khanal/Documents/Bidur Git Repo/padColorimetry/Data/new data/downsampled_image_HSV_32_2400.pkl')\n",
    "    #data= pd.read_pickle('C:/Users/Brinda Khanal/Documents/Bidur Git Repo/padColorimetry/Data/downsampled_feature_vectors_HSV_inner_circle_CNN.pkl')\n",
    "    #data= pd.read_pickle('C:/Users/Brinda Khanal/Documents/Bidur Git Repo/padColorimetry/Data/downsampled_feature_vectors_HSV_CNN.pkl')\n",
    "    #replace_values= { 1:11, 2 : 11, 3 : 11, 4 : 12, 5 : 12, 6 : 12 , 7 : 12, 8 : 13, 9 : 13, 10 : 13} # fuse the labels\n",
    "    #data.replace({'Dilution Factor' : replace_values}, inplace = True)  \n",
    "    # encode the label values into integer type\n",
    "    lab_enc = preprocessing.LabelEncoder()\n",
    "    Label = lab_enc.fit_transform(data['Dilution Factor'])\n",
    "    \n",
    "    feature_vector = data['Feature Vector']\n",
    "    features=[]\n",
    "    for f in feature_vector:\n",
    "        features.append(f)\n",
    "    features = np.array(features)\n",
    "    print(features.shape)\n",
    "\n",
    "    return Label, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_LAB_CNN():\n",
    "    \n",
    "    # load RGB channel data\n",
    "    data= pd.read_pickle('C:/Users/Brinda Khanal/Documents/Bidur Git Repo/padColorimetry/Data/new data/downsampled_image_LAB_32_2400.pkl')\n",
    "    #data= pd.read_pickle('C:/Users/Brinda Khanal/Documents/Bidur Git Repo/padColorimetry/Data/downsampled_feature_vectors_LAB_inner_circle_CNN.pkl')\n",
    "    #data= pd.read_pickle('C:/Users/Brinda Khanal/Documents/Bidur Git Repo/padColorimetry/Data/downsampled_feature_vectors_LAB_CNN.pkl')\n",
    "    #replace_values= { 1:11, 2 : 11, 3 : 11, 4 : 12, 5 : 12, 6 : 12 , 7 : 12, 8 : 13, 9 : 13, 10 : 13} # fuse the labels\n",
    "    #data.replace({'Dilution Factor' : replace_values}, inplace = True) \n",
    "    # encode the label values into integer type\n",
    "    lab_enc = preprocessing.LabelEncoder()\n",
    "    Label = lab_enc.fit_transform(data['Dilution Factor'])\n",
    "    \n",
    "    feature_vector = data['Feature Vector']\n",
    "    features=[]\n",
    "    for f in feature_vector:\n",
    "        features.append(f)\n",
    "    features = np.array(features)\n",
    "    print(features.shape)\n",
    "\n",
    "    return Label, features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the features for the testsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_RGB_test_CNN():\n",
    "    \n",
    "    # load RGB channel data\n",
    "    #data= pd.read_pickle('C:/Users/Brinda Khanal/Documents/Bidur Git Repo/padColorimetry/Data/downsampled_feature_vectors_RGB_CNN_test.pkl')\n",
    "    #data= pd.read_pickle('C:/Users/Brinda Khanal/Documents/Bidur Git Repo/padColorimetry/Data/downsampled_feature_vectors_RGB_inner_circle_CNN_test.pkl')\n",
    "    data= pd.read_pickle('C:/Users/Brinda Khanal/Documents/Bidur Git Repo/padColorimetry/Data/new data/downsampled_image_RGB_32_600.pkl')\n",
    "    #replace_values= { 1:11, 2 : 11, 3 : 11, 4 : 12, 5 : 12, 6 : 12 , 7 : 12, 8 : 13, 9 : 13, 10 : 13} # fuse the labels\n",
    "    #data.replace({'Dilution Factor' : replace_values}, inplace = True) \n",
    "    #data = data.loc[(data['Dilution Factor']==1) | (data['Dilution Factor']==3) | (data['Dilution Factor']==5) | (data['Dilution Factor']==7) | (data['Dilution Factor']==10)]\n",
    "    # encode the label values into integer type\n",
    "    \n",
    "    lab_enc = preprocessing.LabelEncoder()\n",
    "    Label = lab_enc.fit_transform(data['Dilution Factor'])\n",
    "    \n",
    "    feature_vector = data['Feature Vector']\n",
    "    features=[]\n",
    "    for f in feature_vector:\n",
    "        features.append(f)\n",
    "    features = np.array(features)\n",
    "    print(features.shape)\n",
    "    datagen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)\n",
    "    datagen.fit(features)\n",
    "    #features = (features-datagen.mean)/datagen.std\n",
    "    #features= (features-[ 82.73537,  108.89578,  121.84176,   96.675514, 118.18483,  123.833755])/[58.642254, 53.121796, 57.44918,  53.580616, 54.76519,  56.368843]\n",
    "    print (features.shape)\n",
    "\n",
    "\n",
    "    return Label, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_HSV_test_CNN():\n",
    "    \n",
    "    # load RGB channel data\n",
    "    data= pd.read_pickle('C:/Users/Brinda Khanal/Documents/Bidur Git Repo/padColorimetry/Data/new data/downsampled_image_HSV_32_600.pkl')\n",
    "    #data= pd.read_pickle('C:/Users/Brinda Khanal/Documents/Bidur Git Repo/padColorimetry/Data/downsampled_feature_vectors_HSV_inner_circle_CNN_test.pkl')\n",
    "    #data= pd.read_pickle('C:/Users/Brinda Khanal/Documents/Bidur Git Repo/padColorimetry/Data/downsampled_feature_vectors_HSV_CNN_test.pkl')\n",
    "    #replace_values= { 1:11, 2 : 11, 3 : 11, 4 : 12, 5 : 12, 6 : 12 , 7 : 12, 8 : 13, 9 : 13, 10 : 13} # fuse the labels\n",
    "    #data.replace({'Dilution Factor' : replace_values}, inplace = True) \n",
    "    # encode the label values into integer type\n",
    "    lab_enc = preprocessing.LabelEncoder()\n",
    "    Label = lab_enc.fit_transform(data['Dilution Factor'])\n",
    "    \n",
    "    feature_vector = data['Feature Vector']\n",
    "    features=[]\n",
    "    for f in feature_vector:\n",
    "        features.append(f)\n",
    "    features = np.array(features)\n",
    "    print(features.shape)\n",
    "\n",
    "\n",
    "    return Label, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_LAB_test_CNN():\n",
    "    \n",
    "    # load RGB channel data\n",
    "    data= pd.read_pickle('C:/Users/Brinda Khanal/Documents/Bidur Git Repo/padColorimetry/Data/new data/downsampled_image_LAB_32_600.pkl')\n",
    "    #data= pd.read_pickle('C:/Users/Brinda Khanal/Documents/Bidur Git Repo/padColorimetry/Data/downsampled_feature_vectors_LAB_inner_circle_CNN_test.pkl')\n",
    "    #data= pd.read_pickle('C:/Users/Brinda Khanal/Documents/Bidur Git Repo/padColorimetry/Data/downsampled_feature_vectors_LAB_CNN_test.pkl')\n",
    "    #replace_values= { 1:11, 2 : 11, 3 : 11, 4 : 12, 5 : 12, 6 : 12 , 7 : 12, 8 : 13, 9 : 13, 10 : 13} # fuse the labels\n",
    "    #data.replace({'Dilution Factor' : replace_values}, inplace = True) \n",
    "    # encode the label values into integer type\n",
    "    lab_enc = preprocessing.LabelEncoder()\n",
    "    Label = lab_enc.fit_transform(data['Dilution Factor'])\n",
    "    \n",
    "    feature_vector = data['Feature Vector']\n",
    "    features=[]\n",
    "    for f in feature_vector:\n",
    "        features.append(f)\n",
    "    features = np.array(features)\n",
    "    print(features.shape)\n",
    "\n",
    "\n",
    "    return Label, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### function to plot confusion matrix\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    #transpose the matrix to make x-axis True Class and Y-axis Predicted Class\n",
    "    cm= np.transpose(cm)\n",
    "    \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    #print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[0]),\n",
    "           yticks=np.arange(cm.shape[1]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           \n",
    "           #here we are not printing the title\n",
    "           #title=title,\n",
    "           xlabel='True label',\n",
    "           ylabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return fig,ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_csv_test(accuracy,csv_file,remarks):\n",
    "    df_list = []\n",
    "    df_list.extend([accuracy,remarks])\n",
    "    print (df_list)\n",
    "    df=pd.DataFrame(columns=['avg_accuracy','remarks'], data=[df_list])\n",
    "    print (df)\n",
    "    with open(csv_file, 'a') as f:\n",
    "        df.to_csv(f, index= False, header=f.tell()==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_csv(accuracy_list,csv_file,remarks):\n",
    "    avg= np.mean(accuracy_list)\n",
    "    df_list = accuracy_list.copy()\n",
    "    df_list.extend([avg,remarks])\n",
    "    print (df_list)\n",
    "    df=pd.DataFrame(columns=['split1', 'split2','split3','split4','split5','avg_accuracy','remarks'], data=[df_list])\n",
    "    print (df)\n",
    "    with open(csv_file, 'a') as f:\n",
    "        df.to_csv(f, index= False, header=f.tell()==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=6, activation='sigmoid'))\n",
    "model.add(Dense(100, activation='sigmoid'))\n",
    "model.add(Dense(1, activation= 'linear'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# data and labels\n",
    "Labels, Values = load_RGB_train_mean()\n",
    "test_Labels, Values_test= load_RGB_test_mean()\n",
    "\n",
    "\n",
    "# Convert labels to categorical one-hot encoding\n",
    "Labels = keras.utils.to_categorical(Labels, num_classes=10)\n",
    "Labels_test = keras.utils.to_categorical(test_Labels, num_classes=10) \n",
    "\n",
    "\n",
    "# Fit the model\n",
    "model.fit(Values,Labels,epochs=500, batch_size=500)\n",
    "\n",
    "# evaluate the model\n",
    "scores = model.evaluate(Values_test, Labels_test, batch_size=500)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "# calculate predictions\n",
    "predictions = model.predict(Values_test)\n",
    "pred= np.amax(predictions, axis=1)\n",
    "print (pred)\n",
    "indices = np.argmax(predictions, axis=1)\n",
    "print(indices)\n",
    "\n",
    "test_list= np.array([ k[0] for k in test_Labels.values])\n",
    "print (test_list)\n",
    "\n",
    "Accuracy= accuracy_score(test_list,indices)\n",
    "print (\"Accuracy Score: \", Accuracy)\n",
    "print(classification_report(test_list,indices, target_names=[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\"]))\n",
    "fig,ax= plot_confusion_matrix(test_list,indices, classes=[1,2,3,4,5,6,7,8,9,10],title='Confusion matrix, ANN, RGB')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ANN_mean_test(Labels, Values, test_Labels, Values_test, colorspace= \"RGB\"):\n",
    "    \n",
    "    # create model\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, input_dim=6, activation='sigmoid'))\n",
    "    model.add(Dense(100, activation='sigmoid'))\n",
    "    model.add(Dense(3, activation= 'softmax'))\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    # Convert labels to categorical one-hot encoding\n",
    "    Labels = keras.utils.to_categorical(Labels, num_classes=3)\n",
    "    Labels_test = keras.utils.to_categorical(test_Labels, num_classes=3) \n",
    "    \n",
    "    # initialize the weights\n",
    "    keras.initializers.glorot_normal(seed=42)\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(Values,Labels,epochs=500, batch_size=128)\n",
    "\n",
    "    # evaluate the model\n",
    "    scores = model.evaluate(Values_test, Labels_test, batch_size=128)\n",
    "    print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "    # calculate predictions\n",
    "    predictions = model.predict(Values_test)\n",
    "    pred= np.amax(predictions, axis=1)\n",
    "    print (pred)\n",
    "    indices = np.argmax(predictions, axis=1)\n",
    "    print(indices)\n",
    "\n",
    "    test_list= np.array([ k[0] for k in test_Labels.values])\n",
    "    print (test_list)\n",
    "\n",
    "    Accuracy= accuracy_score(test_list,indices)\n",
    "    print (\"Accuracy Score: \", Accuracy)\n",
    "    print(classification_report(test_list,indices, target_names=[\"1\",\"2\",\"3\"]))\n",
    "    fig,ax= plot_confusion_matrix(test_list,indices, classes=[1,2,3],title='Confusion matrix, ANN, '+colorspace)\n",
    "    plt.show()\n",
    "    filename = \"C:/Users/Brinda Khanal/Documents/Bidur Git Repo/padColorimetry/new figures/ANN_test_\" +colorspace+\".png\"\n",
    "    fig.savefig(filename)\n",
    "    return Accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ANN_mean_validation(Labels, Values, colorspace= \"RGB\"):\n",
    "   \n",
    "    \n",
    "\n",
    "    kf=StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "\n",
    "\n",
    "    kf_info= kf.get_n_splits(Values, Labels) # returns the number of splitting iterations in the cross-validator\n",
    "    print(kf_info) \n",
    "    accuracy = []\n",
    "    i=1\n",
    "\n",
    "    for train_index, test_index in kf.split(Values,Labels):\n",
    "        \n",
    "        # create model\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(Dense(100, input_dim=6, activation='sigmoid'))\n",
    "        model.add(Dense(100, activation='sigmoid'))\n",
    "        model.add(Dense(3, activation= 'softmax'))\n",
    "\n",
    "        # Compile model\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "        # Convert labels to categorical one-hot encoding\n",
    "        Labels_train = keras.utils.to_categorical(Labels.loc[train_index], num_classes=3)\n",
    "        Labels_test =  keras.utils.to_categorical(Labels.loc[test_index], num_classes=3)\n",
    "        \n",
    "        \n",
    "        # initialize the weights\n",
    "        keras.initializers.glorot_normal(seed=42)\n",
    "        \n",
    "        # Fit the model\n",
    "        model.fit(Values.loc[train_index],Labels_train,epochs=500, batch_size=128)\n",
    "\n",
    "        # evaluate the model\n",
    "        scores = model.evaluate(Values.loc[test_index], Labels_test, batch_size=128)\n",
    "        print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "\n",
    "        # calculate predictions\n",
    "        predictions = model.predict(Values.loc[test_index])\n",
    "        pred= np.amax(predictions, axis=1)\n",
    "        print (pred)\n",
    "        indices = np.argmax(predictions, axis=1)\n",
    "        print(indices)\n",
    "\n",
    "        test_list= np.array([ k[0] for k in Labels.loc[test_index].values])\n",
    "        print (test_list)\n",
    "\n",
    "        Accuracy= accuracy_score(test_list,indices)\n",
    "        print (\"Accuracy Score: \", Accuracy)\n",
    "        accuracy.append(Accuracy)\n",
    "        print(classification_report(test_list,indices, target_names=[\"1\",\"2\",\"3\"]))\n",
    "        fig,ax= plot_confusion_matrix(test_list,indices, classes=[1,2,3],title='Confusion matrix, ANN, '+colorspace)\n",
    "        plt.show()\n",
    "        filename = \"C:/Users/Brinda Khanal/Documents/Bidur Git Repo/padColorimetry/new figures/ANN_cross_validation_\" +colorspace+\"_split\"+str(i)+\".png\"\n",
    "        fig.savefig(filename)\n",
    "        i+=1\n",
    "        \n",
    "\n",
    "    print (\"Mean Accuracy\", np.mean(accuracy))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def CNN_test(Labels_train, Values_train, test_Labels, Values_test, colorspace= \"RGB\"):\n",
    "    \n",
    "    Labels_train=keras.utils.to_categorical(Labels_train, num_classes=3)\n",
    "    Labels_test=keras.utils.to_categorical(test_Labels, num_classes=3)\n",
    "    \n",
    "    \n",
    "    model = Sequential()\n",
    "    # input: 16x32 images with 3 channels -> (16, 16, 6) tensors.\n",
    "    # this applies 32 convolution filters of size 3x3 each.\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', input_shape=(16,16, 6)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),padding='SAME'))\n",
    "    #model.add(Dropout(0.25))\n",
    "    model.add(SpatialDropout2D(0.25))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),padding='SAME'))\n",
    "    #model.add(Dropout(0.25))\n",
    "    model.add(SpatialDropout2D(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add (Dense(100, activation = 'sigmoid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "    sgd = SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=sgd,metrics=['accuracy'])\n",
    "    \n",
    "    # initialize the weights\n",
    "    keras.initializers.glorot_normal(seed=42)\n",
    "\n",
    "    model.fit(Values_train, Labels_train, batch_size=128, epochs=300)\n",
    "    keras.callbacks.EarlyStopping(monitor='train_loss',\n",
    "                              min_delta=0,\n",
    "                              patience=20,\n",
    "                              verbose=0, mode='auto')\n",
    "    #scores = model.evaluate(Values_train, Labels_train, batch_size=100)\n",
    "    #print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "    # calculate predictions\n",
    "    predictions = model.predict(Values_test)\n",
    "    pred= np.amax(predictions, axis=1)\n",
    "    print (pred)\n",
    "    indices = np.argmax(predictions, axis=1)\n",
    "    print(indices)\n",
    "\n",
    "\n",
    "    print (test_Labels)\n",
    "\n",
    "    Accuracy= accuracy_score(test_Labels,indices)\n",
    "    print (\"Accuracy Score: \", Accuracy)\n",
    "    print(classification_report(test_Labels,indices, target_names=[\"1\",\"2\",\"3\"]))\n",
    "    fig,ax= plot_confusion_matrix(test_Labels,indices, classes=[1,2,3],title='Confusion matrix, ANN, '+ colorspace)\n",
    "    plt.show()\n",
    "    filename = \"C:/Users/Brinda Khanal/Documents/Bidur Git Repo/padColorimetry/new figures/CNN_test_\" +colorspace+\".png\"\n",
    "    fig.savefig(filename)\n",
    "    \n",
    "\n",
    "    return Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def CNN_validation(Labels, Values, colorspace= \"RGB\"):\n",
    "    \n",
    "    \n",
    "\n",
    "    kf=StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "\n",
    "\n",
    "    kf_info= kf.get_n_splits(Values, Labels) # returns the number of splitting iterations in the cross-validator\n",
    "    print(kf_info) \n",
    "    accuracy = []\n",
    "    i=1\n",
    "\n",
    "    for train_index, test_index in kf.split(Values,Labels):\n",
    "    \n",
    "        \n",
    "        model = Sequential()\n",
    "        # input: 16x32 images with 3 channels -> (16, 16, 6) tensors.\n",
    "        # this applies 32 convolution filters of size 3x3 each.\n",
    "        model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(16,16, 6)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2),padding='SAME'))\n",
    "        #model.add(Dropout(0.25))\n",
    "        model.add(SpatialDropout2D(0.25))\n",
    "\n",
    "        model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2),padding='SAME'))\n",
    "        #model.add(Dropout(0.25))\n",
    "        model.add(SpatialDropout2D(0.25))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(256, activation='sigmoid'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add (Dense(100, activation = 'sigmoid'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Dense(10, activation='softmax'))\n",
    "        sgd = SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=sgd ,metrics=['accuracy'])\n",
    "       \n",
    "        # Convert labels to categorical one-hot encoding\n",
    "        Labels_train = keras.utils.to_categorical(Labels[train_index], num_classes=10)\n",
    "        Labels_test =  keras.utils.to_categorical(Labels[test_index], num_classes=10)\n",
    "        \n",
    "        # initialize the weights\n",
    "        keras.initializers.glorot_normal(seed=42)\n",
    "        \n",
    "        \n",
    "        # Fit the model\n",
    "        model.fit(Values[train_index],Labels_train,epochs=300, batch_size=128)\n",
    "        keras.callbacks.EarlyStopping(monitor='train_loss',\n",
    "                              min_delta=0,\n",
    "                              patience=20,\n",
    "                              verbose=0, mode='auto')\n",
    "\n",
    "        # evaluate the model\n",
    "        #scores = model.evaluate(Values[test_index], Labels_test, batch_size=100)\n",
    "        #print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "\n",
    "        # calculate predictions\n",
    "        predictions = model.predict(Values[test_index])\n",
    "        pred= np.amax(predictions, axis=1)\n",
    "        print (pred)\n",
    "        indices = np.argmax(predictions, axis=1)\n",
    "        print(indices)\n",
    "\n",
    "\n",
    "        Accuracy= accuracy_score(Labels[test_index],indices)\n",
    "        print (\"Accuracy Score: \", Accuracy)\n",
    "        accuracy.append(Accuracy)\n",
    "        print(classification_report(Labels[test_index],indices, target_names=[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\"]))\n",
    "        fig,ax= plot_confusion_matrix(Labels[test_index],indices, classes=[1,2,3,4,5,6,7,8,9,10],title='Confusion matrix, ANN, '+ colorspace)\n",
    "        plt.show()\n",
    "        filename = \"C:/Users/Brinda Khanal/Documents/Bidur Git Repo/padColorimetry/new figures/CNN_validation_split\"+str(i) +colorspace+\".png\"\n",
    "        fig.savefig(filename)\n",
    "        i+=1\n",
    "    print (\"Mean Accuracy\", np.mean(accuracy))\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### check accuracy scores for mean colors, test set\n",
    "\n",
    "# data and labels RGB colorspace\n",
    "Labels, Values = load_RGB_train_mean()\n",
    "test_Labels, Values_test= load_RGB_test_mean()\n",
    "accuracy_score_RGB= ANN_mean_test (Labels, Values, test_Labels, Values_test, colorspace= \"RGB\")\n",
    "save_csv_test(accuracy_score_RGB,'test_mean_value.csv','RGB,ANN')\n",
    "\n",
    "# data and labels HSV colorspace\n",
    "Labels, Values = load_HSV_train_mean()\n",
    "test_Labels, Values_test= load_HSV_test_mean()\n",
    "accuracy_score_HSV=ANN_mean_test (Labels, Values, test_Labels, Values_test, colorspace= \"HSV\")\n",
    "save_csv_test(accuracy_score_HSV,'test_mean_value.csv','HSV,ANN')\n",
    "\n",
    "# data and labels LAB colorspace\n",
    "Labels, Values = load_LAB_train_mean()\n",
    "test_Labels, Values_test= load_LAB_test_mean()\n",
    "accuracy_score_LAB=ANN_mean_test (Labels, Values, test_Labels, Values_test, colorspace= \"LAB\")\n",
    "save_csv_test(accuracy_score_LAB,'test_mean_value.csv','LAB,ANN')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### check accuracy scores for mean colors, Validation set\n",
    "\n",
    "# data and labels RGB colorspace\n",
    "Labels, Values = load_RGB_train_mean()\n",
    "accuracy_score_list_RGB=ANN_mean_validation (Labels, Values, colorspace= \"RGB\")\n",
    "save_csv(accuracy_score_list_RGB,'cross_validation_mean_value.csv','RGB,ANN')\n",
    "\n",
    "# data and labels HSV colorspace\n",
    "Labels, Values = load_HSV_train_mean()\n",
    "accuracy_score_list_HSV=ANN_mean_validation (Labels, Values, colorspace= \"HSV\")\n",
    "save_csv(accuracy_score_list_HSV,'cross_validation_mean_value.csv','HSV,ANN')\n",
    "\n",
    "\n",
    "# data and labels LAB colorspace\n",
    "Labels, Values = load_LAB_train_mean()\n",
    "accuracy_score_list_LAB=ANN_mean_validation (Labels, Values, colorspace= \"LAB\")\n",
    "save_csv(accuracy_score_list_LAB,'cross_validation_mean_value.csv','LAB,ANN')\n",
    "\n",
    "ax = sns.boxplot(x=['RGB','HSV','LAB'], y=[accuracy_score_list_RGB,accuracy_score_list_HSV,accuracy_score_list_LAB],palette=\"Set1\", whis= 2)\n",
    "ax.set(title= 'ANN' ,ylabel='Accuracy')\n",
    "filename = \"C:/Users/Brinda Khanal/Documents/Bidur Git Repo/padColorimetry/new figures/bar_plot_ANN.png\"\n",
    "fig = ax.get_figure()\n",
    "fig.savefig(filename)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### check accuarcy scores using CNN, test set\n",
    "\n",
    "# data and labels RGB colorspace\n",
    "Labels_train, Values_train = load_RGB_CNN()\n",
    "test_Labels, Values_test= load_RGB_test_CNN()\n",
    "accuracy_score_RGB= CNN_test(Labels_train, Values_train, test_Labels, Values_test, colorspace= \"RGB\")\n",
    "save_csv_test(accuracy_score_RGB,'test_CNN.csv','RGB,CNN')\n",
    "\n",
    "# data and labels HSV colorspace\n",
    "Labels_train, Values_train = load_HSV_CNN()\n",
    "test_Labels, Values_test= load_HSV_test_CNN()\n",
    "accuracy_score_HSV=CNN_test(Labels_train, Values_train, test_Labels, Values_test, colorspace= \"HSV\")\n",
    "save_csv_test(accuracy_score_HSV,'test_CNN.csv','HSV,CNN')\n",
    "\n",
    "# data and labels LAB colorspace\n",
    "Labels_train, Values_train = load_LAB_CNN()\n",
    "test_Labels, Values_test= load_LAB_test_CNN()\n",
    "accuracy_score_LAB=CNN_test(Labels_train, Values_train, test_Labels, Values_test, colorspace= \"LAB\")\n",
    "save_csv_test(accuracy_score_LAB,'test_CNN.csv','LAB,CNN')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### check accuracy scores using CNN, validation set\n",
    "\n",
    "# data and Labels RGB colorspace\n",
    "Labels_train, Values_train = load_RGB_CNN()\n",
    "accuracy_score_list_RGB=CNN_validation(Labels_train, Values_train, colorspace= \"RGB\")\n",
    "save_csv(accuracy_score_list_RGB,'cross_validation_CNN.csv','RGB,CNN')\n",
    "\n",
    "# data and Labels HSV colorspace\n",
    "Labels_train, Values_train = load_HSV_CNN()\n",
    "accuracy_score_list_HSV= CNN_validation(Labels_train, Values_train, colorspace= \"HSV\")\n",
    "save_csv(accuracy_score_list_HSV,'cross_validation_CNN.csv','HSV,CNN')\n",
    "\n",
    "# data and Labels LAB colorspace\n",
    "Labels_train, Values_train = load_LAB_CNN()\n",
    "accuracy_score_list_LAB= CNN_validation(Labels_train, Values_train, colorspace= \"LAB\")\n",
    "save_csv(accuracy_score_list_LAB,'cross_validation_CNN.csv','LAB,CNN')\n",
    "\n",
    "ax = sns.boxplot(x=['RGB','HSV','LAB'], y=[accuracy_score_list_RGB,accuracy_score_list_HSV,accuracy_score_list_LAB],palette=\"Set1\", whis= 2)\n",
    "ax.set(title= 'Random Forrest' ,ylabel='Accuracy')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
